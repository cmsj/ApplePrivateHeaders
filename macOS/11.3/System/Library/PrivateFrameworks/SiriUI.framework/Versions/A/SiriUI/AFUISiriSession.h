/*
* This header is generated by classdump-dyld 1.0
* on Wednesday, April 28, 2021 at 2:52:32 PM British Summer Time
* Operating System: Version 11.3 (Build 20E232)
* Image Source: /System/Library/PrivateFrameworks/SiriUI.framework/Versions/A/SiriUI
* classdump-dyld is licensed under GPLv3, Copyright Â© 2013-2016 by Elias Limneos.
*/

#import <libobjc.A.dylib/AFAssistantUIService.h>
#import <libobjc.A.dylib/AFSpeechDelegate.h>
#import <libobjc.A.dylib/AFUIStateMachineDelegate.h>
#import <libobjc.A.dylib/AFUISpeechSynthesisLocalDelegate.h>
#import <libobjc.A.dylib/AFUISiriSession.h>

@protocol AFUISiriSession <NSObject>
@required
+(id)currentMicrophoneIdentifier;
+(void)forceAvailabilityStateAvailable:(char)arg1;
-(void)cancelSpeechRequest;
-(void)end;
-(void)preheat;
-(void)clearContext;
-(void)setAlertContext;
-(void)setApplicationContext;
-(void)rollbackClearContext;
-(void)telephonyRequestCompleted;
-(void)forceAudioSessionActive;
-(void)forceAudioSessionInactive;
-(void)recordUIMetrics:(id)arg1;
-(void)sendReplyCommand:(id)arg1;
-(void)setLockState:(unsigned long long)arg1;
-(void)resetContextTypes:(long long)arg1;
-(void)resultDidChangeForAceCommand:(id)arg1;
-(void)requestDidPresentViewForUICommand:(id)arg1;
-(void)requestDidPresentViewForErrorCommand:(id)arg1;
-(void)stopRecordingSpeech;
-(void)startCorrectedRequestWithText:(id)arg1 correctionIdentifier:(id)arg2 userSelectionResults:(id)arg3;
-(void)performAceCommand:(id)arg1;
-(void)performAceCommand:(id)arg1 conflictHandler:(/*^block*/id)arg2;
-(void)startRequestWithOptions:(id)arg1;
-(void)stopRequestWithOptions:(id)arg1;
-(void)updateRequestOptions:(id)arg1;
-(void)recordRequestMetricEvent:(id)arg1 withTimestamp:(double)arg2;

@end


@protocol OS_dispatch_queue, AFUISiriSessionDelegate, AFUISiriSessionLocalDataSource, AFUISiriSessionLocalDelegate, OS_dispatch_group;
@class NSObject, AFUIStateMachine, AFUISpeechSynthesis, NSMutableSet, AFConnection, NSString;

@interface AFUISiriSession : NSObject <AFAssistantUIService, AFSpeechDelegate, AFUIStateMachineDelegate, AFUISpeechSynthesisLocalDelegate, AFUISiriSession> {

	NSObject*<OS_dispatch_queue> _delegateQueue;
	char _currentRequestDidPresent;
	AFUIStateMachine* _stateMachine;
	AFUISpeechSynthesis* _speechSynthesis;
	NSMutableSet* _speechRequestGroupGraveyard;
	/*^block*/id _continuePendingRequest;
	char _sendContextBeforeContinuingSpeechRequest;
	char _eyesFree;
	char _isProcessingAcousticIdRequest;
	id<AFUISiriSessionDelegate> _delegate;
	id<AFUISiriSessionLocalDataSource> _localDataSource;
	id<AFUISiriSessionLocalDelegate> _localDelegate;
	AFConnection* _connection;
	NSObject*<OS_dispatch_group> _currentSpeechRequestGroup;

}

@property (getter=_connection,nonatomic,readonly) AFConnection * connection;                                                                                              //@synthesize connection=_connection - In the implementation block
@property (setter=_setCurrentSpeechRequestGroup:,getter=_currentSpeechRequestGroup,nonatomic,retain) NSObject*<OS_dispatch_group> currentSpeechRequestGroup;              //@synthesize currentSpeechRequestGroup=_currentSpeechRequestGroup - In the implementation block
@property (assign,nonatomic,__weak) id<AFUISiriSessionDelegate> delegate;                                                                                                 //@synthesize delegate=_delegate - In the implementation block
@property (assign,nonatomic,__weak) id<AFUISiriSessionLocalDataSource> localDataSource;                                                                                   //@synthesize localDataSource=_localDataSource - In the implementation block
@property (assign,nonatomic,__weak) id<AFUISiriSessionLocalDelegate> localDelegate;                                                                                       //@synthesize localDelegate=_localDelegate - In the implementation block
@property (assign,getter=isEyesFree,nonatomic) char eyesFree;                                                                                                             //@synthesize eyesFree=_eyesFree - In the implementation block
@property (nonatomic,readonly) char isProcessingAcousticIdRequest;                                                                                                        //@synthesize isProcessingAcousticIdRequest=_isProcessingAcousticIdRequest - In the implementation block
@property (readonly) unsigned long long hash; 
@property (readonly) Class superclass; 
@property (copy,readonly) NSString * description; 
@property (copy,readonly) NSString * debugDescription; 
+(unsigned long long)availabilityState;
+(id)effectiveCoreLocationBundle;
+(id)currentMicrophoneIdentifier;
+(void)forceAvailabilityStateAvailable:(char)arg1 ;
+(void)beginMonitoringSiriAvailability;
-(void)dealloc;
-(id<AFUISiriSessionDelegate>)delegate;
-(void)setDelegate:(id<AFUISiriSessionDelegate>)arg1 ;
-(long long)_state;
-(id)_connection;
-(void)cancelSpeechRequest;
-(void)end;
-(char)_hasActiveRequest;
-(id)_stateMachine;
-(void)preheat;
-(void)clearContext;
-(void)setEyesFree:(char)arg1 ;
-(void)setAlertContext;
-(void)setApplicationContext;
-(void)assistantConnection:(id)arg1 startUIRequestWithText:(id)arg2 completion:(/*^block*/id)arg3 ;
-(void)assistantConnection:(id)arg1 receivedCommand:(id)arg2 completion:(/*^block*/id)arg3 ;
-(void)assistantConnectionDidChangeAudioRecordingPower:(id)arg1 ;
-(void)assistantConnectionRequestWillStart:(id)arg1 ;
-(void)assistantConnection:(id)arg1 requestFailedWithError:(id)arg2 requestClass:(id)arg3 ;
-(void)assistantConnectionRequestFinished:(id)arg1 ;
-(void)assistantConnection:(id)arg1 shouldSpeak:(char)arg2 ;
-(void)assistantConnectionWillStartAcousticIDRequest:(id)arg1 ;
-(void)assistantConnectionDidDetectMusic:(id)arg1 ;
-(void)assistantConnection:(id)arg1 didFinishAcousticIDRequestWithSuccess:(char)arg2 ;
-(void)assistantConnectionSpeechRecordingWillBegin:(id)arg1 ;
-(void)assistantConnection:(id)arg1 speechRecordingDidBeginOnAVRecordRoute:(id)arg2 ;
-(void)assistantConnection:(id)arg1 speechRecordingDidChangeAVRecordRoute:(id)arg2 ;
-(void)assistantConnectionSpeechRecordingDidDetectStartpoint:(id)arg1 ;
-(void)assistantConnection:(id)arg1 speechRecordingPerformTwoShotPromptWithType:(long long)arg2 completion:(/*^block*/id)arg3 ;
-(void)assistantConnectionSpeechRecordingDidEnd:(id)arg1 ;
-(void)assistantConnectionSpeechRecordingDidCancel:(id)arg1 ;
-(void)assistantConnection:(id)arg1 speechRecordingDidFail:(id)arg2 ;
-(void)assistantConnection:(id)arg1 speechRecognized:(id)arg2 ;
-(void)assistantConnection:(id)arg1 speechRecognizedPartialResult:(id)arg2 ;
-(void)_startRequestWithInfo:(id)arg1 ;
-(void)rollbackClearContext;
-(void)telephonyRequestCompleted;
-(void)forceAudioSessionActive;
-(void)forceAudioSessionInactive;
-(void)recordUIMetrics:(id)arg1 ;
-(void)sendReplyCommand:(id)arg1 ;
-(void)assistantConnection:(id)arg1 openApplicationWithBundleID:(id)arg2 URL:(id)arg3 completion:(/*^block*/id)arg4 ;
-(void)assistantConnection:(id)arg1 openURL:(id)arg2 completion:(/*^block*/id)arg3 ;
-(void)assistantConnectionDismissAssistant:(id)arg1 ;
-(char)isEyesFree;
-(char)isListening;
-(void)setLockState:(unsigned long long)arg1 ;
-(id<AFUISiriSessionLocalDataSource>)localDataSource;
-(void)setLocalDataSource:(id<AFUISiriSessionLocalDataSource>)arg1 ;
-(void)resetContextTypes:(long long)arg1 ;
-(void)resultDidChangeForAceCommand:(id)arg1 ;
-(void)requestDidPresentViewForUICommand:(id)arg1 ;
-(void)requestDidPresentViewForErrorCommand:(id)arg1 ;
-(void)stopRecordingSpeech;
-(void)startCorrectedRequestWithText:(id)arg1 correctionIdentifier:(id)arg2 userSelectionResults:(id)arg3 ;
-(void)performAceCommand:(id)arg1 ;
-(id)speechSynthesis;
-(void)stateMachine:(id)arg1 didTransitionFromState:(long long)arg2 forEvent:(long long)arg3 ;
-(id)stateMachine:(id)arg1 descriptionForEvent:(long long)arg2 ;
-(void)_outputVoiceDidChange:(id)arg1 ;
-(void)_siriNetworkAvailabilityDidChange:(id)arg1 ;
-(void)_performBlockWithDelegate:(/*^block*/id)arg1 ;
-(id<AFUISiriSessionLocalDelegate>)localDelegate;
-(void)_startSpeechRequestWithOptions:(id)arg1 ;
-(void)_startContinuityRequestWithInfo:(id)arg1 ;
-(void)_startSpeechPronunciationRequestWithContext:(id)arg1 options:(id)arg2 ;
-(void)_startRequestWithText:(id)arg1 ;
-(void)_startSpeechRequestWithSpeechFileAtURL:(id)arg1 ;
-(void)_discardCurrentSpeechGroup;
-(void)_postInvocationRequestCompletedNotification:(char)arg1 ;
-(void)_setCurrentSpeechRequestGroup:(id)arg1 ;
-(id)_currentSpeechRequestGroup;
-(void)_startRequestWithFinalOptions:(id)arg1 ;
-(id)_preparedSpeechRequestWithRequestOptions:(id)arg1 ;
-(void)setLocalDelegate:(id<AFUISiriSessionLocalDelegate>)arg1 ;
-(void)_didChangeDialogPhase:(id)arg1 ;
-(void)_handleUnlockDeviceCommand:(id)arg1 ;
-(void)_handleRequestUpdateViewsCommand:(id)arg1 ;
-(void)_performTransitionForEvent:(long long)arg1 ;
-(void)_requestDidFinishWithError:(id)arg1 ;
-(void)_continuePendingSpeechRequest;
-(void)_requestContextWithCompletion:(/*^block*/id)arg1 ;
-(float)recordingPowerLevel;
-(void)_requestWillStart;
-(id)underlyingConnection;
-(void)_startRequestWithBlock:(/*^block*/id)arg1 ;
-(void)performAceCommands:(id)arg1 ;
-(void)_performAceCommand:(id)arg1 forRequestUpdateViewsCommand:(id)arg2 afterDelay:(double)arg3 ;
-(void)performAceCommand:(id)arg1 conflictHandler:(/*^block*/id)arg2 ;
-(void)stopCurrentRecordingForSpeechSynthesis:(id)arg1 ;
-(void)speechSynthesisWillStartSpeaking:(id)arg1 ;
-(char)speechSynthesisConnectionIsRecording:(id)arg1 ;
-(void)startRequestWithOptions:(id)arg1 ;
-(void)stopRequestWithOptions:(id)arg1 ;
-(void)updateRequestOptions:(id)arg1 ;
-(void)recordRequestMetricEvent:(id)arg1 withTimestamp:(double)arg2 ;
-(id)initWithConnection:(id)arg1 delegateQueue:(id)arg2 ;
-(void)_startDirectActionRequestWithString:(id)arg1 appID:(id)arg2 withContext:(id)arg3 ;
-(char)isPreventingActivationGesture;
-(char)isProcessingAcousticIdRequest;
@end

